{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.contents import StreamingFileReferenceContent\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# assistant: To analyze the net pension liability change over the years, I need to inspect the contents and structure of the files you uploaded. I’ll start by reviewing the files to extract relevant data for the analysis.\n",
      "\n",
      "```python\n",
      "# Checking the contents and structure of the first uploaded file.\n",
      "import pandas as pd\n",
      "\n",
      "file_path_1 = '/mnt/data/assistant-FgWocR7ZH4caqxofsMcrU5'\n",
      "file_path_2 = '/mnt/data/assistant-Nu5NzJhjsGnVrozbtbKJri'\n",
      "\n",
      "data_1 = pd.ExcelFile(file_path_1)\n",
      "data_1.sheet_names  # Checking the available sheets in the file\n",
      "```\n",
      "\n",
      "# assistant: It seems the file is not recognized as an Excel file. I'll attempt to inspect its content to determine the correct format and proceed accordingly.\n",
      "\n",
      "```python\n",
      "# Checking the raw file type and previewing its content to identify its format.\n",
      "import mimetypes\n",
      "\n",
      "file_type_1 = mimetypes.guess_type(file_path_1)\n",
      "file_type_2 = mimetypes.guess_type(file_path_2)\n",
      "\n",
      "file_type_1, file_type_2\n",
      "```\n",
      "\n",
      "# assistant: The file format is unclear from the guessed type. I'll manually inspect the files further by attempting to parse them as standard formats (e.g., Excel, CSV, or text) to identify their structure. Let's try opening them as CSV files first.\n",
      "\n",
      "```python\n",
      "# Trying to load the files as CSV to explore their content and structure.\n",
      "try:\n",
      "    data_1_csv = pd.read_csv(file_path_1)\n",
      "    is_csv_1 = True\n",
      "except Exception:\n",
      "    is_csv_1 = False\n",
      "\n",
      "try:\n",
      "    data_2_csv = pd.read_csv(file_path_2)\n",
      "    is_csv_2 = True\n",
      "except Exception:\n",
      "    is_csv_2 = False\n",
      "\n",
      "is_csv_1, is_csv_2\n",
      "```\n",
      "\n",
      "# assistant: Both files appear to be in CSV format. Let me preview their content to identify the relevant data fields and proceed with analyzing the net pension liability change.\n",
      "\n",
      "```python\n",
      "# Previewing the first few rows of each file to understand their structure and content.\n",
      "data_1_preview = pd.read_csv(file_path_1).head()\n",
      "data_2_preview = pd.read_csv(file_path_2).head()\n",
      "\n",
      "data_1_preview, data_2_preview\n",
      "```\n",
      "\n",
      "# assistant: The two files contain data organized in tabular format with pension-related information across multiple years. However, the exact column and row that determine the net pension liability change are unclear as the headers and values seem mixed.\n",
      "\n",
      "I'll clean and analyze the structure further to locate net pension liability data within these files.\n",
      "\n",
      "```python\n",
      "# Reloading the data with emphasis on headers to clean and analyze\n",
      "data_1_full = pd.read_csv(file_path_1)\n",
      "data_2_full = pd.read_csv(file_path_2)\n",
      "\n",
      "# Displaying the headers and data to identify useful columns/rows\n",
      "data_1_full.head(), data_2_full.head()\n",
      "```\n",
      "\n",
      "# assistant: Based on the preview, the files contain some pension-related measures across various years, but the values include inconsistent entries (e.g., dollar signs, parentheses for negatives), and the headers are somewhat ambiguous. \n",
      "\n",
      "To locate the net pension liability change, I will attempt to clean the data and search for columns or rows that specifically correspond to this metric.\n",
      "\n",
      "```python\n",
      "# Attempting to locate key columns and rows related to \"net pension liability\"\n",
      "# Renaming unnamed columns for clarity and easier filtering\n",
      "data_1_full.columns = ['Metric'] + [str(col).strip() for col in data_1_full.columns[1:]]\n",
      "data_2_full.columns = ['Metric'] + [str(col).strip() for col in data_2_full.columns[1:]]\n",
      "\n",
      "# Checking both files for rows containing potential references to \"net pension liability\"\n",
      "net_pension_data_1 = data_1_full[data_1_full['Metric'].str.contains(\"pension liability\", case=False, na=False)]\n",
      "net_pension_data_2 = data_2_full[data_2_full['Metric'].str.contains(\"pension liability\", case=False, na=False)]\n",
      "\n",
      "net_pension_data_1, net_pension_data_2\n",
      "```\n",
      "\n",
      "# assistant: From the analysis:\n",
      "\n",
      "1. The first file doesn't contain data explicitly related to \"net pension liability.\"\n",
      "2. The second file has several relevant rows under the **Metric** column, including:\n",
      "   - Net Change in Total Pension Liability\n",
      "   - Net Pension Liability\n",
      "   - Total Pension Liability (Beginning/Ending)\n",
      "\n",
      "These rows span multiple years and appear suitable for evaluating changes in net pension liability. I'll extract and calculate the changes over the years for \"Net Pension Liability.\"\n",
      "\n",
      "```python\n",
      "# Extracting the \"Net Pension Liability\" values from the second file and cleaning them for analysis\n",
      "net_pension_liability = net_pension_data_2.loc[net_pension_data_2['Metric'].str.contains(\"Net Pension Liability\", case=False, na=False)]\n",
      "\n",
      "# Dropping irrelevant columns and cleaning dollar signs and commas for numeric calculations\n",
      "liability_values = net_pension_liability.iloc[:, 1:].applymap(\n",
      "    lambda x: float(str(x).replace('$', '').replace(',', '').strip()) if not pd.isnull(x) else None\n",
      ")\n",
      "\n",
      "# Assessing year-on-year changes in net pension liability\n",
      "liability_changes = liability_values.diff(axis=1)\n",
      "liability_changes.columns = liability_values.columns  # Matching column names for clarity\n",
      "\n",
      "liability_changes.sort_index(axis=1), liability_values.sort_index(axis=1)\n",
      "```\n",
      "\n",
      "# assistant: It seems some entries in the relevant columns include percentages or other non-numeric values, which are causing issues in computation. I'll filter out non-numeric entries before calculating the changes in net pension liability over the years. Let me clean this further.\n",
      "\n",
      "```python\n",
      "# Cleaning data to retain only numeric or monetary values for analysis\n",
      "def clean_numeric(value):\n",
      "    try:\n",
      "        # Only process values that can be converted to numbers (e.g., removing symbols and spaces)\n",
      "        return float(str(value).replace('$', '').replace(',', '').strip())\n",
      "    except ValueError:\n",
      "        # Return None for non-numeric values (e.g., percentages)\n",
      "        return None\n",
      "\n",
      "# Applying cleaning to the liability values\n",
      "clean_liability_values = net_pension_liability.iloc[:, 1:].applymap(clean_numeric)\n",
      "\n",
      "# Assessing year-on-year changes in net pension liability\n",
      "clean_liability_changes = clean_liability_values.diff(axis=1)\n",
      "clean_liability_changes.columns = clean_liability_values.columns  # Matching column names for clarity\n",
      "\n",
      "clean_liability_changes.sort_index(axis=1), clean_liability_values.sort_index(axis=1)\n",
      "```\n",
      "\n",
      "# assistant: The cleaned data for \"Net Pension Liability\" is now available. Here's the breakdown:\n",
      "\n",
      "1. **Total Net Pension Liability Values (by Year):**\n",
      "   - **2014:** $11,295,000\n",
      "   - **2015:** $14,740,098\n",
      "   - **2016:** $19,750,061\n",
      "   - **2017:** $23,872,639\n",
      "   - **2018:** $26,663,148\n",
      "   - **2019:** $29,144,251\n",
      "   - **2020:** $30,683,076\n",
      "   - **2021:** $20,334,432\n",
      "   - **2022:** $34,409,085\n",
      "   - **2023:** $36,198,888\n",
      "\n",
      "2. **Year-over-Year Changes in Net Pension Liability:**\n",
      "   - **2014 → 2015:** +$3,445,098\n",
      "   - **2015 → 2016:** +$5,009,963\n",
      "   - **2016 → 2017:** +$4,072,578\n",
      "   - **2017 → 2018:** +$2,791,509\n",
      "   - **2018 → 2019:** +$2,481,103\n",
      "   - **2019 → 2020:** +$1,034,865\n",
      "   - **2020 → 2021:** -$10,348,644 (decrease)\n",
      "   - **2021 → 2022:** +$10,536,446\n",
      "   - **2022 → 2023:** +$1,789,803\n",
      "\n",
      "Let me know if you'd like a graphical representation or further analysis of these changes!\n",
      "\n",
      "\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Extracting year-over-year changes and values for plotting\n",
      "years = clean_liability_values.columns.astype(str)\n",
      "values = clean_liability_values.iloc[0]\n",
      "changes = clean_liability_changes.iloc[0]\n",
      "\n",
      "# Creating a dual-axis plot for net pension liability values and changes\n",
      "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
      "\n",
      "# Plotting total values\n",
      "ax1.set_title(\"Net Pension Liability Over Years\", fontsize=16)\n",
      "ax1.plot(years, values, marker='o', color='b', label=\"Net Pension Liability (Total)\")\n",
      "ax1.set_xlabel(\"Year\", fontsize=12)\n",
      "ax1.set_ylabel(\"Net Pension Liability (Total)\", color='b', fontsize=12)\n",
      "ax1.tick_params(axis='y', labelcolor='b')\n",
      "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
      "ax1.legend(loc=\"upper left\")\n",
      "\n",
      "# Creating a twin Y-axis for changes\n",
      "ax2 = ax1.twinx()\n",
      "ax2.bar(years, changes, color='orange', alpha=0.6, label=\"Yearly Change in Liability\")\n",
      "ax2.set_ylabel(\"Change in Liability\", color=\"orange\", fontsize=12)\n",
      "ax2.tick_params(axis='y', labelcolor=\"orange\")\n",
      "ax2.legend(loc=\"upper right\")\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "# assistant: The graph represents the **Net Pension Liability** and its **Yearly Changes** across the years:\n",
      "\n",
      "1. The blue line illustrates the **total liability values**, showing an overall increasing trend with some fluctuations over time.\n",
      "2. The orange bars represent the **year-over-year changes**, highlighting significant increases and decreases, such as the drop in 2021.\n",
      "\n",
      "Let me know if additional insights or modifications are needed!\n",
      "File saved to: c:\\Users\\akunanbaeva\\OneDrive - Microsoft\\CalPERS\\agents\\assistant-TUzFoowgugbkZJtqycxYnY.png\n",
      "\n",
      "# assistant: You're welcome! Feel free to reach out if you have any other questions in the future. Have a great day! 😊\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.contents import StreamingFileReferenceContent\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Use the current working directory (notebook directory) instead of __file__\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "csv_file_path_1 = os.path.join(parent_dir, \"data_processing\", \"csv_tables\", \"merged_analysis_of_financial_experience.csv\")\n",
    "csv_file_path_2 = os.path.join(parent_dir, \"data_processing\", \"csv_tables\", \"merged_schedules_of_changes_in_net_pension_liability.csv\")\n",
    "\n",
    "async def download_file_content(agent: AzureAssistantAgent, file_id: str):\n",
    "    try:\n",
    "        # Fetch the content of the file using the provided method\n",
    "        response_content = await agent.client.files.content(file_id)\n",
    "\n",
    "        # Use the current working directory for file saving\n",
    "        file_path = os.path.join(\n",
    "            os.getcwd(),  # current working directory\n",
    "            f\"{file_id}.png\",  # modify as needed for file extension or naming\n",
    "        )\n",
    "\n",
    "        # Save content to a file\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response_content.content)\n",
    "\n",
    "        print(f\"File saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading file {file_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "async def download_response_image(agent: AzureAssistantAgent, file_ids: list[str]):\n",
    "    if file_ids:\n",
    "        for file_id in file_ids:\n",
    "            await download_file_content(agent, file_id)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create the client using Azure OpenAI resources and configuration\n",
    "    client, model = AzureAssistantAgent.setup_resources()\n",
    "\n",
    "    # Upload the files to the client\n",
    "    file_ids: list[str] = []\n",
    "    for path in [csv_file_path_1, csv_file_path_2]:\n",
    "        with open(path, \"rb\") as file:\n",
    "            file = await client.files.create(file=file, purpose=\"assistants\")\n",
    "            file_ids.append(file.id)\n",
    "\n",
    "    # Get the code interpreter tool and resources\n",
    "    code_interpreter_tools, code_interpreter_tool_resources = AzureAssistantAgent.configure_code_interpreter_tool(\n",
    "        file_ids=file_ids\n",
    "    )\n",
    "\n",
    "    # Create the assistant definition\n",
    "    definition = await client.beta.assistants.create(\n",
    "        model=model,\n",
    "        instructions=\"\"\"\n",
    "            Analyze the available data to provide an answer to the user's question.\n",
    "            Always format response using markdown.\n",
    "            Always include a numerical index that starts at 1 for any lists or tables.\n",
    "            Always sort lists in ascending order.\n",
    "            \"\"\",\n",
    "        name=\"SampleAssistantAgent\",\n",
    "        tools=code_interpreter_tools,\n",
    "        tool_resources=code_interpreter_tool_resources,\n",
    "    )\n",
    "\n",
    "    # Create the agent using the client and the assistant definition\n",
    "    agent = AzureAssistantAgent(\n",
    "        client=client,\n",
    "        definition=definition,\n",
    "    )\n",
    "\n",
    "    thread: AssistantAgentThread = None\n",
    "\n",
    "    try:\n",
    "        is_complete: bool = False\n",
    "        file_ids: list[str] = []\n",
    "        while not is_complete:\n",
    "            user_input = input(\"User:> \")\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            if user_input.lower() == \"exit\":\n",
    "                is_complete = True\n",
    "                break\n",
    "\n",
    "            is_code = False\n",
    "            last_role = None\n",
    "            async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "                current_is_code = response.metadata.get(\"code\", False)\n",
    "\n",
    "                if current_is_code:\n",
    "                    if not is_code:\n",
    "                        print(\"\\n\\n```python\")\n",
    "                        is_code = True\n",
    "                    print(response.content, end=\"\", flush=True)\n",
    "                else:\n",
    "                    if is_code:\n",
    "                        print(\"\\n```\")\n",
    "                        is_code = False\n",
    "                        last_role = None\n",
    "                    if hasattr(response, \"role\") and response.role is not None and last_role != response.role:\n",
    "                        print(f\"\\n# {response.role}: \", end=\"\", flush=True)\n",
    "                        last_role = response.role\n",
    "                    print(response.content, end=\"\", flush=True)\n",
    "                file_ids.extend([\n",
    "                    item.file_id for item in response.items if isinstance(item, StreamingFileReferenceContent)\n",
    "                ])\n",
    "                thread = response.thread\n",
    "            if is_code:\n",
    "                print(\"```\\n\")\n",
    "            print()\n",
    "\n",
    "            await download_response_image(agent, file_ids)\n",
    "            file_ids.clear()\n",
    "\n",
    "    finally:\n",
    "        print(\"\\nCleaning up resources...\")\n",
    "        # Delete uploaded files\n",
    "        [await client.files.delete(file_id) for file_id in file_ids]\n",
    "        if thread:\n",
    "            await thread.delete()\n",
    "        await client.beta.assistants.delete(agent.id)\n",
    "\n",
    "# Run the main coroutine in the notebook\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'sk26'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
