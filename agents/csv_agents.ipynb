{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.contents import StreamingFileReferenceContent\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# AuthorRole.ASSISTANT: To identify the total market value, I need to examine the uploaded files to determine how this information is structured. Let me first read the content of the uploaded files and analyze them.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the first file to preview its contents\n",
      "file_path_1 = '/mnt/data/assistant-6KbTksHiFtcT7XvN5MRs35'\n",
      "data_1 = pd.read_excel(file_path_1)\n",
      "data_1.head()\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: It seems the first uploaded file might not have a recognizable format or extension directly compatible with the default Excel reader. Let me inspect the file more closely using another method to determine its structure.\n",
      "\n",
      "I'll first try reading it as a CSV or another format if needed.\n",
      "\n",
      "```python\n",
      "# Attempt to load the file as a CSV to inspect its format\n",
      "try:\n",
      "    data_1 = pd.read_csv(file_path_1)\n",
      "    data_1.head()\n",
      "except Exception as e:\n",
      "    str(e)\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The file does not seem to be in CSV format either. I will determine the format of the file to choose the correct method for reading it.\n",
      "\n",
      "```python\n",
      "import mimetypes\n",
      "\n",
      "# Determine the file type of the first uploaded file\n",
      "file_type_1 = mimetypes.guess_type(file_path_1)\n",
      "file_type_1\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The file type of the first uploaded file could not be determined automatically. I will now examine the second uploaded file to ensure we understand its format and structure.\n",
      "\n",
      "```python\n",
      "# Load the second file to preview its contents\n",
      "file_path_2 = '/mnt/data/assistant-9sWcsJ692Yiy4dg26GvAwu'\n",
      "try:\n",
      "    data_2 = pd.read_excel(file_path_2)\n",
      "    data_2.head()\n",
      "except Exception as e:\n",
      "    str(e)\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The second file may also be in an unsupported format or require specific handling. I will analyze its file type to determine how to proceed.\n",
      "\n",
      "```python\n",
      "# Determine the file type of the second uploaded file\n",
      "file_type_2 = mimetypes.guess_type(file_path_2)\n",
      "file_type_2\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: Both files have undetermined file types, which suggests they might be in a proprietary or less common format. I will attempt to identify their structure using raw file inspection techniques to extract relevant content.\n",
      "\n",
      "```python\n",
      "# Examine the raw file content for both files to identify their structure\n",
      "with open(file_path_1, 'rb') as f1, open(file_path_2, 'rb') as f2:\n",
      "    content_1 = f1.read(1024)  # Read the first 1024 bytes of the first file\n",
      "    content_2 = f2.read(1024)  # Read the first 1024 bytes of the second file\n",
      "\n",
      "content_1, content_2\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The raw content inspection reveals that the files are likely structured in a tabular format resembling CSV, albeit with unconventional formatting such as embedded textual headers or special symbols. I will attempt to parse the files with explicit delimiters to extract the relevant information.\n",
      "\n",
      "Let me begin by loading the files as comma-delimited text data.\n",
      "\n",
      "```python\n",
      "# Reload the first file explicitly as a CSV with potential adjustments\n",
      "data_1_alternative = pd.read_csv(file_path_1, delimiter=\",\", header=None)\n",
      "data_1_alternative.head()\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The first file is successfully loaded and appears to contain tabular data with headers and yearly values spanning different financial metrics. To calculate the total market value, I will search for the relevant column or row containing this information.\n",
      "\n",
      "Now Iâ€™ll do the same for the second file.\n",
      "\n",
      "```python\n",
      "# Reload the second file explicitly as a CSV with potential adjustments\n",
      "data_2_alternative = pd.read_csv(file_path_2, delimiter=\",\", header=None)\n",
      "data_2_alternative.head()\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The second file also contains tabular data with financial metrics across different years. To compute the total market value, I will identify the relevant entries in both datasets. Starting with the first file, I will locate rows or columns that likely represent market values.\n",
      "\n",
      "```python\n",
      "# Search for rows or columns in the first file containing potential \"market value\" references\n",
      "market_value_data_1 = data_1_alternative[data_1_alternative[0].str.contains(\"market value\", case=False, na=False)]\n",
      "market_value_data_1\n",
      "```\n",
      "\n",
      "# AuthorRole.ASSISTANT: The first file contains references to \"Market Value of Assets\" across multiple rows. To determine the total market value, I will extract and aggregate these values where appropriate.\n",
      "\n",
      "Similarly, I will search for market value references in the second file.\n",
      "\n",
      "```python\n",
      "# Search for rows or columns in the second file containing potential \"market value\" references\n",
      "market_value_data_2 = data_2_alternative[data_2_alternative[0].str.contains(\"market value\", case=False, na=False)]\n",
      "market_value_data_2```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.contents import StreamingFileReferenceContent\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Use the current working directory (notebook directory) instead of __file__\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "csv_file_path_1 = os.path.join(parent_dir, \"data_processing\", \"csv_tables\", \"merged_analysis_of_financial_experience.csv\")\n",
    "csv_file_path_2 = os.path.join(parent_dir, \"data_processing\", \"csv_tables\", \"merged_schedules_of_changes_in_net_pension_liability.csv\")\n",
    "\n",
    "async def download_file_content(agent: AzureAssistantAgent, file_id: str):\n",
    "    try:\n",
    "        # Fetch the content of the file using the provided method\n",
    "        response_content = await agent.client.files.content(file_id)\n",
    "\n",
    "        # Use the current working directory for file saving\n",
    "        file_path = os.path.join(\n",
    "            os.getcwd(),  # current working directory\n",
    "            f\"{file_id}.png\",  # modify as needed for file extension or naming\n",
    "        )\n",
    "\n",
    "        # Save content to a file\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response_content.content)\n",
    "\n",
    "        print(f\"File saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading file {file_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "async def download_response_image(agent: AzureAssistantAgent, file_ids: list[str]):\n",
    "    if file_ids:\n",
    "        for file_id in file_ids:\n",
    "            await download_file_content(agent, file_id)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create the client using Azure OpenAI resources and configuration\n",
    "    client, model = AzureAssistantAgent.setup_resources()\n",
    "\n",
    "    # Upload the files to the client\n",
    "    file_ids: list[str] = []\n",
    "    for path in [csv_file_path_1, csv_file_path_2]:\n",
    "        with open(path, \"rb\") as file:\n",
    "            file = await client.files.create(file=file, purpose=\"assistants\")\n",
    "            file_ids.append(file.id)\n",
    "\n",
    "    # Get the code interpreter tool and resources\n",
    "    code_interpreter_tools, code_interpreter_tool_resources = AzureAssistantAgent.configure_code_interpreter_tool(\n",
    "        file_ids=file_ids\n",
    "    )\n",
    "\n",
    "    # Create the assistant definition\n",
    "    definition = await client.beta.assistants.create(\n",
    "        model=model,\n",
    "        instructions=\"\"\"\n",
    "            Analyze the available data to provide an answer to the user's question.\n",
    "            Always format response using markdown.\n",
    "            Always include a numerical index that starts at 1 for any lists or tables.\n",
    "            Always sort lists in ascending order.\n",
    "            \"\"\",\n",
    "        name=\"SampleAssistantAgent\",\n",
    "        tools=code_interpreter_tools,\n",
    "        tool_resources=code_interpreter_tool_resources,\n",
    "    )\n",
    "\n",
    "    # Create the agent using the client and the assistant definition\n",
    "    agent = AzureAssistantAgent(\n",
    "        client=client,\n",
    "        definition=definition,\n",
    "    )\n",
    "\n",
    "    thread: AssistantAgentThread = None\n",
    "\n",
    "    try:\n",
    "        is_complete: bool = False\n",
    "        file_ids: list[str] = []\n",
    "        while not is_complete:\n",
    "            user_input = input(\"User:> \")\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            if user_input.lower() == \"exit\":\n",
    "                is_complete = True\n",
    "                break\n",
    "\n",
    "            is_code = False\n",
    "            last_role = None\n",
    "            async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "                current_is_code = response.metadata.get(\"code\", False)\n",
    "\n",
    "                if current_is_code:\n",
    "                    if not is_code:\n",
    "                        print(\"\\n\\n```python\")\n",
    "                        is_code = True\n",
    "                    print(response.content, end=\"\", flush=True)\n",
    "                else:\n",
    "                    if is_code:\n",
    "                        print(\"\\n```\")\n",
    "                        is_code = False\n",
    "                        last_role = None\n",
    "                    if hasattr(response, \"role\") and response.role is not None and last_role != response.role:\n",
    "                        print(f\"\\n# {response.role}: \", end=\"\", flush=True)\n",
    "                        last_role = response.role\n",
    "                    print(response.content, end=\"\", flush=True)\n",
    "                file_ids.extend([\n",
    "                    item.file_id for item in response.items if isinstance(item, StreamingFileReferenceContent)\n",
    "                ])\n",
    "                thread = response.thread\n",
    "            if is_code:\n",
    "                print(\"```\\n\")\n",
    "            print()\n",
    "\n",
    "            await download_response_image(agent, file_ids)\n",
    "            file_ids.clear()\n",
    "\n",
    "    finally:\n",
    "        print(\"\\nCleaning up resources...\")\n",
    "        # Delete uploaded files\n",
    "        [await client.files.delete(file_id) for file_id in file_ids]\n",
    "        if thread:\n",
    "            await thread.delete()\n",
    "        await client.beta.assistants.delete(agent.id)\n",
    "\n",
    "# Run the main coroutine in the notebook\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'sk26'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
